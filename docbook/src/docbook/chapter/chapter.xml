<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xml:lang="en" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns5="http://www.w3.org/1998/Math/MathML"
         xmlns:ns4="http://www.w3.org/2000/svg"
         xmlns:ns3="http://www.w3.org/1999/xhtml"
         xmlns:ns="http://docbook.org/ns/docbook">
  <info>
    <title>Cascading - Leveraging Scalability</title>
  </info>

  <para>Cascading is an application programming interface (API) that allows
  developers to build increasingly complex, production quality, data
  processing applications for execution in Hadoop clusters.</para>

  <para>The Cascading project was started during the late Summer of 2007, with
  its first public release, Version 0.1.0, in January 2008. By the time this
  chapter is published, it will have reached Version 1.0, after over a year of
  continuous development, testing, and refinement. Binaries and source code
  can be downloaded from the project website, <link
  xlink:href="http://www.cascading.org/">http://www.cascading.org/</link>.</para>

  <para>The Cascading project was started because it was immediately obvious
  that the MapReduce model does not scale organizationally. MapReduce is
  difficult for developers to "think" in when faced with real-world
  applications. And it is at the wrong granularity for creating efficient,
  composable applications that can be shared between users.</para>

  <para>To solve the first criticism, Cascading traded in MapReduce keys and
  values for a simple field names and data tuple model. For the second,
  Cascading departs from Map and Reduce by introducing some alternative
  operations; Functions, Filters, Aggregators, and Buffers.</para>

  <para>Though many alternatives began to emerge before and after the initial
  public release of Cascading, Cascading was designed to be complimentary to
  all of them. All these alternative frameworks have some pre and post
  conditions or expectations. For example, data must be pre-formatted,
  filtered, and/or imported into the Hadoop File System (HDFS). It is quite a
  simple endeavor to have Cascading manage and prepare or import data into
  these alternative frameworks as necessary.</para>

  <section>
    <info>
      <title>Fields and Tuples</title>
    </info>

    <para>The MapReduce model uses keys and values to link input data to the
    Map function, the Map function to the Reduce function, and the Reduce
    function to the output data.</para>

    <para>But as we know, real-world Hadoop applications are usually more than
    one MapReduce job chained together. Consider the canonical word count
    example implemented in MapReduce. If you needed to sort the numeric counts
    in descending order, not an unlikely requirement, it would need to be done
    in a second MapReduce job.</para>

    <para>So, in the abstract, keys and values not only bind Map to Reduce,
    but Reduce to the next Map, and then to the next optional Reduce, and so
    on. When you implement enough of these chained MapReduce applications, you
    start to see a well defined set of key/value manipulations used over and
    over again.</para>

    <para>Cascading both leverages these emergent patterns and simultaneously
    abstracts their complexity away.</para>

    <para>In part this is accomplished by abstracting away keys and values and
    replacing them with tuples that have corresponding field names, similar in
    concept to tables and column names in a Relational Database. Additionally,
    Cascading expands on MapReduce with additional operators that work against
    field names and tuple values.</para>

    <para>Below is a short summary of the main concepts in Cascading, please
    see the Cascading User Guide for a more in depth presentation of the
    Cascading processing model.</para>

    <para>To recap, keys and values are reduced to:</para>

    <mediaobject>
      <imageobject role="fo">
        <imagedata contentwidth="1.5in" fileref="images/fields-tuples.svg"></imagedata>
      </imageobject>

      <imageobject role="html">
        <imagedata contentwidth="1.5in" fileref="images/fields-tuples.png"></imagedata>
      </imageobject>
    </mediaobject>

    <para><variablelist>
        <varlistentry>
          <term>Fields</term>

          <listitem>
            <para>Fields are a collection of either
            <classname>String</classname> names (like "first_name"), numeric
            positions (like 2, or -1, for the third and last position,
            respectively), or a combination of both.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Tuple</term>

          <listitem>
            <para>A Tuple is simply an array of
            <classname>java.lang.Comparable</classname> objects. A Tuple is
            very much like a database row or record.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <para>And streams of these fields and tuples are manipulated with the
    elements or pipes (as in "pipes and filters"):</para>

    <mediaobject>
      <imageobject role="fo">
        <imagedata contentwidth="2in" fileref="images/pipes.svg"></imagedata>
      </imageobject>

      <imageobject role="html">
        <imagedata contentwidth="2in" fileref="images/pipes.png"></imagedata>
      </imageobject>
    </mediaobject>

    <para><variablelist>
        <varlistentry>
          <term>Each</term>

          <listitem>
            <para>The Each pipe processes a single input Tuple at a time, but
            may return zero (0) or more result Tuples for every input Tuple.
            The Each pipe may apply either a Function or a Filter to the input
            Tuple.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>GroupBy</term>

          <listitem>
            <para>The GroupBy pipe groups Tuples based on the values of a
            given set of field names. It behaves just like the SQL <code>group
            by</code> statement. The GroupBy can also merge multiple inpust
            tuple streams, if they all share the same field names.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>CoGroup</term>

          <listitem>
            <para>The CoGroup pipe both joins multiple tuple streams by the
            values of a given set of field names, it also groups the Tuples by
            those values. The all join types and custom joins are supported.
            And more than two streams may be joined simultaneously.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Every</term>

          <listitem>
            <para>The Every pipe processes a single group of Tuples at a time,
            where the group share a common sub-set of Tuple values. And it may
            return zero (0) or more result Tuples for that grouping for every
            input grouping. The Every pipe may apply either an Aggregator or a
            Buffer to the input Tuple grouping.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <para>All these pipes are chained together by the developer into "pipe
    assemblies". Where each assembly can have many input Tuple streams
    (sources) and many output Tuple streams (sinks).</para>

    <mediaobject>
      <imageobject role="fo">
        <imagedata contentwidth="5in" fileref="images/pipe-assembly.svg"></imagedata>
      </imageobject>

      <imageobject role="html">
        <imagedata contentwidth="5in" fileref="images/pipe-assembly.png"></imagedata>
      </imageobject>
    </mediaobject>

    <para>On the surface this might seem more complex than the traditional
    MapReduce model. And admitedly there are more concepts here than Map,
    Reduce, Key, and Value. But in practice, as implemented in Hadoop, there
    are many more concepts that must all work in tandem to affect different
    behaviors.</para>

    <para>For example, if a developer wanted to provide a "secondary sorting"
    of reduce values, they would need to implement Map, Reduce, a composite
    Key (two Keys nested in a parent Key), Value, Partitioner, an "output
    value grouping" Comparator, and an "output key" Comparator. All of which
    would be coupled to one another in varying ways, and very likely
    non-reusable in subsequent jobs.</para>

    <para>In Cascading, this would be one line of code: <code>new GroupBy(
    &lt;previous&gt;, &lt;grouping fields&gt;, &lt;secondary sorting
    fields&gt;)</code>. Where <code>previous</code> is the pipe that came
    before.</para>
  </section>

  <section>
    <info>
      <title>Operations</title>
    </info>

    <para>As mentioned above, Cascading departs from MapReduce by introducing
    alternative operations that either are applied to individual Tuples or
    groups of Tuples.</para>

    <mediaobject>
      <imageobject role="fo">
        <imagedata contentwidth="2in" fileref="images/operations.svg"></imagedata>
      </imageobject>

      <imageobject role="html">
        <imagedata contentwidth="2in" fileref="images/operations.png"></imagedata>
      </imageobject>
    </mediaobject>

    <para><variablelist>
        <varlistentry>
          <term>Function</term>

          <listitem>
            <para>A Function operates on individual input Tuples and may
            return zero (0) or more output Tuples for every one input.
            Functions are applied by the Each pipe.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Filter</term>

          <listitem>
            <para>A Filter is a special kind of Function that returns a
            boolean value if the current input Tuple should be removed from
            the Tuple stream. A Function could serve this purpose, but the
            Filter is optimized for this case, and many filters can be grouped
            by "logical" filters like And, Or, Xor, and Not, rapidly creating
            more complex filtering operations.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Aggregator</term>

          <listitem>
            <para>An Aggregator performs some function against a group of
            Tuples, where the grouped Tuples are grouped by a common set of
            field values. For example, all Tuples have the same "last-name"
            field value. Common Aggregator functions would be Sum, Count,
            Average, Max, and Min.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Buffer</term>

          <listitem>
            <para>A Buffer is similar to the Aggregator, except it is
            optimized to act as a "sliding window" across a group of Tuples.
            This is useful when the developer needs to efficiently insert
            missing values in an ordered set of Tuples (like a missing date or
            duration). Usually Aggregator is the operation of choice when
            working with groups of Tuples since many Aggregators can be
            chained together very efficiently, but sometimes a Buffer is the
            best tool for the job.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <para>Operations are bound to pipes when the pipe assembly is created. The
    Each and Every pipe provides a simple mechanism for selecting some or all
    values out of a input Tuple before being passed to its child operation.
    And there is a simple mechanism for merging the operation results with the
    original input Tuple to create a the output Tuple. Without going into
    great detail, this allows for each operation to only care about argument
    Tuple values and fields, not the whole set of fields in the current input
    Tuple. This allows for operations to be reusable across applicaitions the
    same way Java methods can be reusable.</para>

    <para>For example, in Java, a method declared as <code>join( String first,
    String second )</code> is more abstract than <code>join( Person person
    )</code>. In the second case, the <code>join</code> function must know
    about the <code>Person</code> object, in the first case, it is agnostic to
    where the data came from. Cascading operations exhibit this same
    quality.</para>

    <para>&lt;insert pipe-assembly-operations image&gt;</para>
  </section>

  <section>
    <info>
      <title>Absorbing Complexity</title>
    </info>

    <para>Now take a step back and see what this new model has given us. Or
    better yet, what it has taken away.</para>

    <para>You see, we no longer think in terms of MapReduce jobs, or Mapper
    and Reducer interface implementations. And how to bind or link subsequent
    MapReduce jobs to the ones that preceede them.</para>

    <para>Because of this, developers can build applications of arbitrary
    granularity. They can start with a small application that just filters a
    log file, but then can iteratively build up more features into the
    application as needed.</para>

    <para></para>
  </section>

  <section>
    <info>
      <title>Production Quality</title>
    </info>

    <para></para>
  </section>
</chapter>
