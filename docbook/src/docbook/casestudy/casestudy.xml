<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xml:lang="en" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns5="http://www.w3.org/1998/Math/MathML"
         xmlns:ns4="http://www.w3.org/2000/svg"
         xmlns:ns3="http://www.w3.org/1999/xhtml"
         xmlns:ns="http://docbook.org/ns/docbook">
  <info>
    <title>Cascading</title>
  </info>

  <para>Cascading is an open source Java library and application programming
  interface (API) which provides an abstraction layer for MapReduce. It allows
  developers to build complex, mission-critical, data processing applications
  that run on Hadoop clusters.</para>

  <para>The Cascading project began in the summer of 2007 with its first
  public release, Version 0.1, launched in January 2008. Version 1.0 was
  released in January 2009. Binaries, source code, and add-on modules can be
  downloaded from the project website, http://www.cascading.org/</para>

  <para>"Map" and "Reduce" operations offer powerful primitives. However, they
  tend to be at the wrong level of granularity for creating sophisticated,
  highly composable code which can be shared among different developers.
  Moreover, many developers find it difficult to "think" in terms of MapReduce
  when faced with real-world applications.</para>

  <para>To address the first issue, Cascading substitutes the "keys" and
  "values" used in MapReduce with simple field names and a data tuple model --
  where a tuple is simply a list of values. For the second issue, Cascading
  departs from "Map" and "Reduce" operations directly by introducing higher
  level abstractions as alternatives; Functions, Filters, Aggregators, and
  Buffers.</para>

  <para>Other alternatives began to emerge at about the same time as the
  project's initial public release, but Cascading was designed to complement
  them. Consider that most of these alternative frameworks impose pre- and
  post-conditions, or other expectations.</para>

  <para>For example, in several other MapReduce tools you must pre-format,
  filter, or import your data into the Hadoop File System (HDFS) prior to
  running the application. That step of preparing the data must be performed
  outside of the programming abstraction. In contrast, Cascading provides
  means to prepare and manage your data using Sources, Sinks, Taps, etc., all
  as integral parts of the programming abstraction.</para>

  <para>This case study begins with an introduction to the main concepts of
  Cascading, then finishes with an overview of how ShareThis (<link
  xlink:href="http://www.sharethis.com/">http://www.sharethis.com</link>) uses
  Cascading in their infrastructure.</para>

  <para>Please see the Cascading User Guide on the project website for a more
  in-depth presentation of the Cascading processing model.</para>

  <section>
    <info>
      <title>Fields, Tuples, and Pipes</title>
    </info>

    <para>The MapReduce model uses keys and values to link input data to the
    Map function, the Map function to the Reduce function, and the Reduce
    function to the output data.</para>

    <para>But as we know, real-world Hadoop applications are usually more than
    one MapReduce job chained together. Consider the canonical word count
    example implemented in MapReduce. If you needed to sort the numeric counts
    in descending order, not an unlikely requirement, it would need to be done
    in a second MapReduce job.</para>

    <figure xml:id="fig.mr-count-sort">
      <title>Counting and Sorting in MapReduce</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="5in"
                     fileref="images/mr-count-sort.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="5in"
                     fileref="images/mr-count-sort.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>So, in the abstract, keys and values not only bind Map to Reduce,
    but Reduce to the next Map, and then to the next Reduce, and so on. That
    is, key/value pairs are sourced from input files and stream through chains
    of Map and Reduce operations and finally rest in an output file. When you
    implement enough of these chained MapReduce applications, you start to see
    a well defined set of key/value manipulations used over and over again to
    modify the key/value data stream.</para>

    <para>Cascading simplifies this by abstracting away keys and values and
    replacing them with tuples that have corresponding field names, similar in
    concept to tables and column names in a Relational Database. And during
    processing, streams of these Fields and Tuples are then manipulated as
    they pass through user defined operations linked together by Pipes.</para>

    <figure xml:id="fig.chained-pipes">
      <title>Pipes linked by Fields and Tuples</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="5in"
                     fileref="images/chained-pipes.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="5in"
                     fileref="images/chained-pipes.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>So, MapReduce keys and values are reduced to:</para>

    <para><variablelist>
        <varlistentry>
          <term xreflabel="Fields" xml:id="fields">Fields</term>

          <listitem>
            <para>Fields are a collection of either
            <classname>String</classname> names (like "first_name"), numeric
            positions (like 2, or -1, for the third and last position,
            respectively), or a combination of both. Very much like column
            names. So Fields are used to declare the names of values in a
            Tuple, and to select values by name from a Tuple. The later is
            like a SQL <code>select</code> call.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term xreflabel="Tuple" xml:id="tuple">Tuple</term>

          <listitem>
            <para>A Tuple is simply an array of
            <classname>java.lang.Comparable</classname> objects. A Tuple is
            very much like a database row or record.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <para>And the Map and Reduce operations are abstracted behind one or more
    Pipe instances.</para>

    <figure xml:id="fig.pipes">
      <title>Pipe Types</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="3in"
                     fileref="images/pipes.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="3in"
                     fileref="images/pipes.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The <code>Each</code> pipe processes a single input Tuple at a time,
    but may return zero (0) or more result Tuples for every input Tuple and
    may apply either a Function or a Filter to the input Tuple. The
    <code>GroupBy</code> pipe groups Tuples based on the values of a given set
    of field names. It behaves just like the SQL <code>group by</code>
    statement. It can also merge multiple input tuple streams into a single
    stream, if they all share the same field names. The <code>CoGroup</code>
    pipe both joins multiple tuple streams by the values of a given set of
    field names, it also groups the Tuples by those values. All join types
    (inner, outer, etc) and even custom joins are supported and more than two
    streams may be joined simultaneously. The <code>Every</code> pipe
    processes a single grouping of Tuples at a time, where the group shares a
    common sub-set of Tuple values. It may return zero (0) or more result
    Tuples for that grouping for every input grouping and may apply either an
    Aggregator or a Buffer to the grouping. The <code>SubAssembly</code> pipe
    allows for nesting of assemblies inside a single pipe, which are in turn
    nested in more complex assemblies.</para>

    <para>All these pipes are chained together by the developer into "pipe
    assemblies". Where each assembly can have many input Tuple streams
    (sources) and many output Tuple streams (sinks).</para>

    <figure xml:id="fig.pipe-assembly">
      <title>A Simple Pipe Assembly</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/pipe-assembly.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/pipe-assembly.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>On the surface this might seem more complex than the traditional
    MapReduce model. And admitedly there are more concepts here than Map,
    Reduce, Key, and Value. But in practice, as implemented in Hadoop, there
    are many more concepts that must all work in tandem to provide different
    behaviors.</para>

    <para>For example, if a developer wanted to provide a "secondary sorting"
    of reducer values, they would need to implement Map, Reduce, a "composite"
    Key (two Keys nested in a parent Key), Value, Partitioner, an "output
    value grouping" Comparator, and an "output key" Comparator. All of which
    would be coupled to one another in varying ways, and very likely
    non-reusable in subsequent jobs.</para>

    <para>In Cascading, this would be one line of code:<code>new GroupBy(
    &lt;previous&gt;, &lt;grouping fields&gt;, &lt;secondary sorting
    fields&gt;)</code>. Where <code>previous</code> is the pipe that came
    before.</para>
  </section>

  <section>
    <info>
      <title>Operations</title>
    </info>

    <para>As mentioned above, Cascading departs from MapReduce by introducing
    alternative operations that either are applied to individual Tuples or
    groups of Tuples.</para>

    <figure xml:id="fig.operations">
      <title>Operation Types</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="2.5in"
                     fileref="images/operations.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="2.5in"
                     fileref="images/operations.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para><variablelist>
        <varlistentry>
          <term xreflabel="Function" xml:id="function">Function</term>

          <listitem>
            <para>A Function operates on individual input Tuples and may
            return zero (0) or more output Tuples for every one input.
            Functions are applied by the Each pipe.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term xreflabel="Filter" xml:id="filter">Filter</term>

          <listitem>
            <para>A Filter is a special kind of Function that returns a
            boolean value if the current input Tuple should be removed from
            the Tuple stream. A Function could serve this purpose, but the
            Filter is optimized for this case, and many filters can be grouped
            by "logical" filters like And, Or, Xor, and Not, rapidly creating
            more complex filtering operations.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term xreflabel="Aggregator" xml:id="aggregator">Aggregator</term>

          <listitem>
            <para>An Aggregator performs some operation against a group of
            Tuples, where the grouped Tuples are grouped by a common set of
            field values. For example, all Tuples have the same "last-name"
            field value. Common Aggregator implementations would be Sum,
            Count, Average, Max, and Min.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term xreflabel="Buffer" xml:id="buffer">Buffer</term>

          <listitem>
            <para>A Buffer is similar to the Aggregator, except it is
            optimized to act as a "sliding window" across all the Tuples in a
            unique grouping. This is useful when the developer needs to
            efficiently insert missing values in an ordered set of Tuples
            (like a missing date or duration), or create a running average.
            Usually Aggregator is the operation of choice when working with
            groups of Tuples since many Aggregators can be chained together
            very efficiently, but sometimes a Buffer is the best tool for the
            job.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <para>Operations are bound to pipes when the pipe assembly is
    created.</para>

    <figure xml:id="fig.pipe-assembly-operations">
      <title>An Assembly of Operations</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/pipe-assembly-operations.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/pipe-assembly-operations.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The Each and Every pipe provides a simple mechanism for selecting
    some or all values out of a input Tuple before being passed to its child
    operation. And there is a simple mechanism for merging the operation
    results with the original input Tuple to create the output Tuple. Without
    going into great detail, this allows for each operation to only care about
    argument Tuple values and fields, not the whole set of fields in the
    current input Tuple. Subsequently, operations can be reusable across
    applications the same way Java methods can be reusable.</para>

    <para>For example, in Java, a method declared as <code>concatenate( String
    first, String second ) </code> is more abstract than<code>concatenate(
    Person person )</code>. In the second case, the <code>concatenate()</code>
    function must "know" about the <code>Person</code> object, in the first
    case, it is agnostic to where the data came from. Cascading operations
    exhibit this same quality.</para>
  </section>

  <section>
    <info>
      <title>Taps, Schemes, and Flows</title>
    </info>

    <para>In many of the above diagrams, there are references to "sources" and
    "sinks". In Cascading all data is read from or written to
    <classname>Tap</classname> instances, but is converted to and from Tuple
    instances via <classname>Scheme</classname> instances.</para>

    <para><variablelist>
        <varlistentry>
          <term xreflabel="Tap" xml:id="tap">Tap</term>

          <listitem>
            <para>A Tap is responsible for the "how" and "where" parts of
            accessing data. For example, is the data on HDFS or the "local"
            file system. In Amazon S3 or over HTTP.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term xreflabel="Scheme" xml:id="scheme">Scheme</term>

          <listitem>
            <para>A Scheme is responsible for reading raw data and converting
            it to a Tuple and/or writing a Tuple out into raw data. Where this
            "raw" data can be lines of text, Hadoop binary "sequence" files,
            or some proprietary format.</para>
          </listitem>
        </varlistentry>
      </variablelist> Note that Taps are not part of a pipe assembly, and so
    they are not a type of<classname>Pipe</classname>.</para>

    <para>But they are connected with pipe assemblies when they are made
    cluster executable. When a pipe assembly is connected with the necessary
    number of source and sink Tap instances, we get a Flow.</para>

    <para><variablelist>
        <varlistentry>
          <term xreflabel="Flow" xml:id="flow">Flow</term>

          <listitem>
            <para>A Flow is created when a pipe assembly is connected with its
            required number of source and sink taps, and the Taps either emit
            or capture the field names the pipe assembly expects. That is, if
            a Tap emits a Tuple with the field name "line" (by reading data
            from a file on HDFS), the head of the pipe assembly must be
            expecting a "line" value as well. Otherwise the process that
            connects the pipe assembly with the Taps will immeidately fail
            with an error.</para>
          </listitem>
        </varlistentry>
      </variablelist> So pipe assemblies are really data process definitions,
    and are not "executable" on their own. They must be connected to source
    and sink Tap instances before they can run on a cluster. This separation
    between Taps and pipe assemblies is what makes Cascading so
    powerful.</para>

    <figure xml:id="fig.flow">
      <title>A Flow</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/flow.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/flow.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>If you think of pipe assemblies to be like a Java Class, then a Flow
    is like a Java Object instance. That is, the same pipe assembly can be
    "instantiated" many times into new Flows, in the same application, without
    fear of any interference between them. This allows pipe assemblies to be
    created and shared like standard Java libraries.</para>
  </section>

  <section>
    <info>
      <title>Cascading in Practice</title>
    </info>

    <para>Now that we know what Cascading is and have a good idea how it
    works, what does an application written in Cascading look like?</para>

    <example>
      <title>Word Count and Sort</title>

      <xi:include href="word-count-sort.xml" />

      <calloutlist>
        <callout arearefs="ex.wcs.source.scheme">
          <para>We create a new <xref linkend="scheme" /> that can read simple
          text files, and emits a new <xref linkend="tuple" /> for each line
          in a field named "line", as declared by the <xref
          linkend="fields" /> instance.</para>
        </callout>

        <callout arearefs="ex.wcs.sink.scheme">
          <para>We create a new <classname>Scheme</classname> that can write
          simple text files, and expects a <classname>Tuple</classname> with
          any number of fields/values. If more than one value, they will be
          TAB delimited in the output file.</para>
        </callout>

        <callout arearefs="ex.wcs.source ex.wcs.sink">
          <para>We create source and sink <xref linkend="tap" /> instances
          that reference the input file and output directory, respectively.
          The sink <classname>Tap</classname> will overwrite any file that may
          already exist.</para>
        </callout>

        <callout arearefs="ex.wcs.pipe">
          <para>We construct the head of our pipe assembly, and name it
          "wordcount". This name is used to bind the source and sink taps to
          the assembly. Multiple heads or tails would require unique
          names.</para>
        </callout>

        <callout arearefs="ex.wcs.each">
          <para>We construct an Each pipe with a <xref linkend="function" />
          that will parse the "line" field into a new
          <classname>Tuple</classname> for each word encountered.</para>
        </callout>

        <callout arearefs="ex.wcs.group.word">
          <para>We construct a GroupBy pipe that will create a new
          <classname>Tuple</classname> grouping for each unique value in the
          field "word".</para>
        </callout>

        <callout arearefs="ex.wcs.every">
          <para>We construct an Every pipe with an <xref
          linkend="aggregator" /> that will count the number of Tuples in
          every unique word group. The result is stored in a field named
          "count".</para>
        </callout>

        <callout arearefs="ex.wcs.group.count">
          <para>We construct a <classname>GroupBy</classname> pipe that will
          create a new <classname>Tuple</classname> grouping for each unique
          value in the field "count", and secondary sort each value in the
          field "word". The result will be a list of "count" and "word" values
          with "count" sorted in increasing order.</para>
        </callout>

        <callout arearefs="ex.wcs.connect ex.wcs.run">
          <para>We connect the pipe assembly to its sources and sinks into a
          <xref linkend="flow" />, and then execute the Flow on the
          cluster.</para>
        </callout>
      </calloutlist>
    </example>

    <para>In the example above, we count the words encounterd in the input
    document, and we sort the counts in their natural order (ascending). And
    if some words have the same "count" value, these words are sorted in their
    natural order (alphabetical).</para>

    <para>One obvious problem with this example is that some words might have
    upper-case letters, for example, "the" and "The" when the word becomes at
    the beginning of a sentence. So we might decide to insert a new operation
    to force all the words to lower case, but we realize that all future
    applications that need to parse words from documents should have the same
    behavior, so we decide to create a reusable pipe sub-assembly, just like
    we would by creating a sub-routine in a traditional application.</para>

    <example>
      <title>Creating a SubAssembly</title>

      <xi:include href="word-count-sort-subassembly.xml" />

      <calloutlist>
        <callout arearefs="ex.wcs.subclass">
          <para>We subclass the SubAssembly class, which is itself a kind of
          Pipe.</para>
        </callout>

        <callout arearefs="ex.wcs.expression">
          <para>We create a Java expression function that will call
          <methodname>toLowerCase()</methodname> on the
          <classname>String</classname> value in the field named "word". We
          must also pass in the Java type the expression expects "word" to be,
          in this case,<classname>String</classname>. ( <link
          xlink:href="http://www.janino.net/">http://www.janino.net/ </link>
          is used under the covers)</para>
        </callout>

        <callout arearefs="ex.wcs.tails">
          <para>We must tell the <classname>SubAssembly</classname> superclass
          who the tail ends of our pipe sub-assembly are.</para>
        </callout>
      </calloutlist>
    </example>

    <para>First, we create a SubAssembly pipe to hold our "parse words" pipe
    assembly. Since this is a Java class, it can be reused in any other
    application, as long as there is an incoming field named "word". Note
    there are ways to make this function even more generic, but they are
    covered in the Cascading User Guide.</para>

    <example>
      <title>Extending Word Count and Sort with a SubAssembly</title>

      <xi:include href="word-count-sort-sub.xml" />

      <calloutlist>
        <callout arearefs="ex.wcs.subassembly">
          <para>We replace the <classname>Each</classname> from the previous
          example with our <classname>ParseWordsAssembly</classname>
          pipe.</para>
        </callout>
      </calloutlist>
    </example>

    <para>Finally, we just substitute in our new SubAssembly right where the
    previous Every and word parser function was used in the previous example.
    This nesting can continue as deep as necessary.</para>
  </section>

  <section>
    <info>
      <title>MapReduce Planner</title>
    </info>

    <para>Now take a step back and see what this new model has given us. Or
    better yet, what it has taken away.</para>

    <para>You see, we no longer think in terms of MapReduce jobs, or Mapper
    and Reducer interface implementations. And how to bind or link subsequent
    MapReduce jobs to the ones that preceede them. During runtime the
    Cascading "planner" figures out the optimal way to partition the pipe
    assembly into MapReduce jobs, and manages the linkages between
    them.</para>

    <figure xml:id="fig.pipe-assembly-mapreduce">
      <title>How a Flow Translates to Chained MapReduce Jobs</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/pipe-assembly-mapreduce.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/pipe-assembly-mapreduce.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Because of this, developers can build applications of arbitrary
    granularity. They can start with a small application that just filters a
    log file, but then can iteratively build up more features into the
    application as needed.</para>

    <para>Since Cascading is an API and not a syntax like SQL, it is more
    flexible. First off, developers can create Domain Specific Languages
    (DSLs) using their favorite language, like Groovy, JRuby, Jython, Scala,
    and others (see the project site for examples). Second, developers can
    extend various parts of Cascading, like allowing custom Thrift or JSON
    objects to be read and written to and allowing them to be passed through
    the Tuple stream.</para>
  </section>

  <section>
    <info>
      <title>Mission Critical Features</title>
    </info>

    <para>No doubt Cascading can be used for ad-hoc, single use, applications.
    But it really shines when large complex processes need to be created that
    need a higher level of robustness. A robustness expected from production
    quality applications.</para>

    <para>Here are a few of these features:</para>

    <para><variablelist>
        <varlistentry>
          <term>Stream Assertions</term>

          <listitem>
            <para>Stream assertions are just like Java assertions and unit
            tests all rolled up. A pipe assembly can be assembled with
            assertions built into them. These assertions can test for null
            values in an argument Tuple, or if the values match some regular
            expression pattern. If the assertion fails, the process can
            optionally fail, or it can save the bad input Tuple to a new file
            on HDFS. If assertions aren't wanted, Cascading can remove them at
            runtime so they don't slow things down on your production
            system.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Failure Traps</term>

          <listitem>
            <para>Failure traps are like Java Exception handlers. If an
            operation fails unexpectedly, the input Tuple that caused the
            failure can be saved off to a file for later debugging. This
            features works great with stream assertions.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Events</term>

          <listitem>
            <para>Events allow for external code and/or systems to be notified
            when a new process starts, completes, or fails.</para>
          </listitem>
        </varlistentry>

        <varlistentry>
          <term>Dependency Scheduling</term>

          <listitem>
            <para>In Cascading an application can create any number of Flows
            and execute them simultaneously. If one Flow depends on the output
            of a previous Flow, Cascading offers up an utility called a
            Cascade that allows for all these processes to be scheduled in
            dependency order.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>
  </section>

  <section>
    <info>
      <title>Hadoop and Cascading at ShareThis</title>
    </info>

    <para>ShareThis is a sharing network that makes it simple to share any
    online content. With the click of a button on a webpage or browser
    plug-in, ShareThis allows users to seamlessly access their contacts and
    networks from anywhere online and share the content through email, IM,
    Facebook, Digg, mobile SMS, etc. without ever leaving the current page.
    Publishers can deploy the ShareThis button to tap the serviceâ€™s universal
    sharing capabilities to drive traffic, stimulate viral activity and track
    the sharing of online content. ShareThis also simplifies social media
    services by reducing clutter on web pages and providing instant
    distribution of content across social networks, affiliate groups, and
    communities.</para>

    <para>As ShareThis users share pages and information through the online
    widgets, a continuous stream of events enter the ShareThis network. These
    events are first filtered and processed, and then handed to various
    back-end systems including AsterData, HyperTable, and Katta.</para>

    <para>The volume of these event can be huge, too large to process with
    tradtiional systems. This data can also be very "dirty" thanks to
    "injection attacks" from rogue systems, browser bugs, or faulty widgets.
    ShareThis chose to deploy Hadoop as the pre-processing front-end to their
    back-end systems. And to use Amazon Web Services to host their servers, on
    the Elastic Computing Cloud (EC2), and provide long term storage, on the
    Simple Storage Service (S3). With an eye towards leveraging Elastic
    MapReduce (EMR).</para>

    <figure xml:id="fig.sharethis-logprocessing">
      <title>The ShareThis Log Processing Pipeline</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/sharethis-logprocess.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/sharethis-logprocess.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>In this overview we will focus on the "log processing pipeline". The
    log processing pipeline simply takes data stored in an S3 bucket,
    processes it (described below), and stores the results back into another
    bucket. Simple Queue Service (SQS) is used to coordinate the events that
    mark the start and completion of data processing runs. Downstream other
    processes pull data that load AsterData, pull URL lists from Hypertable to
    source a web crawl, or to pull crawled page data to create Lucene indexes
    for use by Katta. Note Hadoop is central to the ShareThis architecture. It
    is used to coordinate the processing and movement of data between
    architectural components.</para>

    <para>With Hadoop as the front-end, all the event logs can be parsed,
    filtered, cleaned, and organized by a set of rules before ever being
    loaded into the AsterData cluster or used by any other component.
    AsterData is a clustered data-warehouse that can support large data-sets
    and allow for complex ad-hoc queries using a standard SQL syntax.
    ShareThis chose to clean and prepare the incoming data-sets on the Hadoop
    cluster and then to load that data into the AsterData cluster for ad-hoc
    analysis and reporting. Though possible with AsterData, it made much sense
    to use Hadoop as the first stage in the processing pipleline to offset
    load on the main data-warehouse. Cascading was chosen as the primary data
    processing API to simplify the development process, codify the
    coordination of data between components, and as the developer facing
    interface to those components.</para>

    <para>For developers, Cascading made it easy to start with a simple
    unit-test (by sub-classing cascading.ClusterTestCase) that did simple text
    parsing and then to layer in more processing rules while keeping the
    application logically organized for maintenance. Cascading aided this
    organization in a couple ways. First, stand-alone operations (Functions,
    Filter, etc) could be written and tested independently. Second, the
    application was segemented into stages, one for parsing, one for rules,
    and a final stage for binning/collating the data, all via the SubAssembly
    base class described above.</para>

    <para>The data coming from the ShareThis loggers looks a lot like Apache
    logs with date/timestamps, share URL's, referrer URL's, and a bit of
    meta-data. To use the data for analysis downstream the URLs needed to be
    un-packed (parsing query-string data, domain names, etc). So a top level
    SubAssembly was created to encapsulate the parsing, and child
    SubAssemblies were nested inside to handle specific fields if they were
    sufficiently complex to parse.</para>

    <para>The same was done for applying rules. As every Tuple passed through
    the rules SubAssembly, it was marked as "bad" if any of the rules were
    triggered. Along with the "bad" tag, a description of why the record was
    bad was added to the Tuple for later review.</para>

    <para>Finally a splitter SubAssembly was created to do two things. First,
    to allow for the tuple stream to split into two, one stream for "good"
    data and one for "bad" data. Second, the splitter binned the data into
    intervals, for example, every hour. To do this, only two operations were
    necessary. The first to create the interval from the 'timestamp' value
    already present in the stream, and the second to use the 'interval' and
    'good/bad' meta-data to create a directory path, for example, "05/good/"
    where "05" is 5am and "good" means the tuple passed all the rules. This
    path would then be used by the Cascading TemplateTap, a special Tap that
    can dynamically output tuple streams to different locations based on
    values in the Tuple. In this case, the TemplateTap used the "path" value
    to create the final output path.</para>

    <para>The developers also created a fourth SubAssembly, this one to apply
    Cascading Assertions during unit-testing. These assertions double checked
    that rules and parsing SubAssemblies did their job.</para>

    <para>In the unit test below we see the the splitter isn't being tested,
    it is added in another integration test not shown.</para>

    <example>
      <title>Unit Testing a Flow</title>

      <xi:include href="sharethis-unittest.xml" />
    </example>

    <para>For integration and deployment, many of the features built into
    Cascading allowed for easier integration with external systems and for
    greater process tolerance.</para>

    <para>In production, all the SubAssemblies are joined and planned into a
    Flow, but instead of just source and sink Taps, trap Taps were planned in.
    Normally when a operation throws an exception from a remote Mapper or
    Reducer task, the Flow will fail and kill all its managed MapReduce jobs.
    When a Flow has traps, any exceptions are caught and the data causing the
    exception is saved to the Tap associated with the current trap. Then the
    next Tuple is processed without stopping the Flow. Sometimes you want your
    Flows to fail on errors, but in this case, the ShareThis developers knew
    they could go back and look at the "failed" data and update thier unit
    tests while the production system kept running. Losing a few hours of
    processing time was worse than losing a couple bad records.</para>

    <para>Using Cascading's event listeners, Amazon SQS could be integrated.
    When a Flow finsihed, a message is sent to notify other systems there is
    data ready to be picked up from Amazon S3. On failure, a different message
    is sent alterting other processes.</para>

    <figure xml:id="fig.sharethis-logprocessing-flow">
      <title>The ShareThis Log Processing Flow</title>

      <mediaobject>
        <imageobject role="fo">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/sharethis-logprocess-flow.svg"></imagedata>
        </imageobject>

        <imageobject role="html">
          <imagedata align="center" contentwidth="6in"
                     fileref="images/sharethis-logprocess-flow.png"></imagedata>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The remaining downstream processes pick up where the log processing
    pipeline leaves off on different independent clusters. The log processing
    pipeline today runs once a day, so there is no need to keep a 100 node
    cluster sitting around for the 23 hours it has nothing to do. So it is
    decommissioned and recommissioned 24 hours later. In the future, it would
    be trivial to increase this interval on smaller clusters to every 6 hours,
    or 1 hour, as the business demands. Independently other clusters are
    booting and shutting down at different intervals based on the needs of the
    business unit responsible for that component. For example, the crawler
    mentioned above may run continuously on a small cluster with a companion
    Hypertable cluster. This on-demand model works very well with Hadoop where
    each cluster can be tuned for the kind of workload it is expected to
    handle.</para>
  </section>

  <section>
    <info>
      <title>Summary</title>
    </info>

    <para>Hadoop is a very powerful platform for processing and coordinating
    the movement of data across various architectural components. Its only
    drawback is that the primary computing model is MapReduce.</para>

    <para>Cascading aims to help developers build powerful applications
    quickly and simply, through a well reasoned API, without needing to think
    in MapReduce. While leaving the heavy lifting of data distribution and
    replication, and distributed process mangement and liveness to
    Hadoop.</para>
  </section>
</chapter>
