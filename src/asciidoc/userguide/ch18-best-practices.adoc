:toc2:
:doctitle: {_doctitle} - Cascading Best Practices

== Cascading Best Practices

=== Unit Testing

Discrete testing of each Operation, pipe assembly, and application is a must.

The [classname]+cascading.CascadingTestCase+ provides a number of static helper
methods.

When testing custom Operations, use the [methodname]+invokeFunction()+,
[methodname]+invokeFilter()+, [methodname]+invokeAggregator()+, and
[methodname]+invokeBuffer()+ methods.

When testing Flows, use the [methodname]+validateLength()+ methods. There are
quite a few of them, and collectively they offer great flexibility. All of them
read the sink tap, validate that it is the correct length and has the correct
[classname]+Tuple+ size, and check to see whether the values match a given
regular expression pattern.

It is also possible to write tests that are independent of the underlying
platform. Any unit test should subclass [classname]+cascading.PlatformTestCase+
located in the [code]+cascading-platform-x.y.z-tests.jar+ file.

Any platform to be tested against should be added to the [code]+CLASSPATH+ as
well. [classname]+PlatformTestCase+ searches the [code]+CLASSPATH+ for all
available platforms and runs each test on the subclass against each platform
found.

See the Cascading platform unit tests for examples, all of which adhere to the
naming convention of [code]+*PlatformTest.java+.

NOTE: For Maven users, be sure to add the [code]+tests+ classifier to any
dependencies. Note that the [code]+cascading-platform+ project has no main code,
but does have only tests, so it must be retrieved via the [code]+tests+
classifier.

=== Flow Granularity

Although using one large [classname]+Flow+ may result in slightly more efficient
performance, it's advisable to use a more modular and flexible approach. Such an
approach involves creating medium-sized Flows with well-defined responsibilities
and passing all the resulting interdependent Flows to a [classname]+Cascade+ to
sequence and execute as a single unit.

Similarly, using the [classname]+TextDelimited+ [classname]+Scheme+ (or any
custom format designed for long-term archival) between [classname]+Flow+
instances allows you to hand off intermediate data to other systems for
reporting or QA purposes, incurring a minimal performance penalty while
remaining compatible with other tools.

TIP: Visit http://cascading.org/extensions/ for a list of available file formats
suitable for data archival or debugging.

=== SubAssemblies, not Factories

When developing your applications, use [classname]+SubAssembly+ subclasses, not
"factory" methods. The resulting code is much easier to read and test.

NOTE: The [classname]+Object+ constructors are "factories", so there isn't much
reason to build frameworks to duplicate what a constructor already does. Of
course, there are exceptional cases in which you don't have the option to use a
[classname]+SubAssembly+, but in practice they are rare.

=== Logical Responsibilities for SubAssemblies

SubAssemblies provide a very convenient means to co-locate similar or related
responsibilities into a single place. For example, it's simple to use a
[classname]+ParsingSubAssembly+ and a [classname]+RulesSubAssembly+, where the
first is responsible solely for parsing incoming [classname]+Tuple+ streams (log
files for example), and the second applies rules to decide whether a given
[classname]+Tuple+ should be discarded or marked as bad.

Additionally, in your unit tests you can create a
[classname]+TestAssertionsSubAssembly+ that simply inlines various
[classname]+ValueAssertions+ and [classname]+GroupAssertions+. The practice of
inlining assertions directly in your SubAssemblies is also important, but
sometimes it makes sense to have more tests outside of the business logic.

=== Java Operators in Field Names

There are a few Operations in Cascading (e.g., [classname]+ExpressionFunction+
and [classname]++ExpressionFilter++) that compile and apply Java expressions as
needed during processing. In these expressions, Operation argument field names
are used as variable names in the expression.

For this reason, be sure to create field names without characters that cause
compilation errors if they are used in an expression. For example, "first-name"
is a valid field name for use with Cascading, but might result in the expression
[code]+first-name.trim()+, which would cause a compilation error.

[[debugging-planner]]
=== Debugging Planner Failures

The [classname]+FlowConnector+ sometimes fails when attempting to plan a
[classname]+Flow+. If the error message given by [classname]+PlannerException+
is vague, use the [code]+PlannerException.writeDOT()+ method to export a
representation of the internal pipe assembly.

DOT files can be opened with Graphviz or OmniGraffle. The plans in these files
are only partial, but the graphic renderings show you where the Cascading
planner failed.

Note that you can also create a DOT file from a [classname]+Flow+ by using
[code]+Flow.writeDOT()+ to better understand how the planner has modified your
business logic.

If the above methods do not provide insight, the new Cascading 3.0 planner has a
much improved debugging framework.

When running tests, set the following:

  -Dtest.traceplan.enabled=true

If you are on Mac OS X and have installed Graphviz, DOT files can be converted
to PDF automatically. To enable this feature, set:

  -Dutil.dot.to.pdf.enabled=true

Optionally, for stand-alone applications, statistics and tracing can be enabled
selectively when the following properties are passed to the
[classname]+FlowConnector+:

* `cascading.planner.stats.path` - outputs detailed statistics about execution
time of the planner
* `cascading.planner.plan.path` - basic planner information
* `cascading.planner.plan.transforms.path` - detailed information about each
rule

=== Optimizing Joins

==== Key Value Cardinality

When joining two streams via a [classname]+CoGroup+ pipe, try to put the larger
stream in the leftmost argument to the [classname]+CoGroup+.

The reason for this is that joining multiple streams requires some accumulation
of values associated with the current key before the join operator can begin,
but the leftmost stream is not accumulated. Consequently, this technique should
improve the performance of most joins.

NOTE: The issues isn't file size specifically, but key to value cardinality. If
one side  of the join has 'one to one' or 'one to few' key to value cardinality,
that side of the join should be right-most. If one side has a 'one to many'
relationship, it should be left-most so the values aren't loaded into memory.

==== Declare Type Information

As of *3.1*, Cascading will leverage that type information to improve
serialization performance during CoGroup (and GroupBy) operations.

With declared type information, Cascading no longer is required to store type
information with every tuple value during serialization. Additionally this type
information helps enforce the canonical type stored in the tuple.

=== Debugging Streams

When creating complex assemblies, it's safe to embed
<<ch16-operations.adoc#debug-function,[classname]+Debug+>> Operations at
appropriate debug levels as needed. To avoid wasting resources, use the planner
to remove the [classname]+Debug+>> Operations at runtime for production and
staging runs.

[[handling-bad-data]]
=== Handling Good and Bad Data

Corrupt data often enters raw data streams. For instance, bad content may be
fetched from the web via a crawler upstream, or a bug may have leaked into a
browser widget that sends user behavior information back for analysis. Whatever
the cause, it's a good practice to define a set of rules for identifying and
managing questionable records.

It is tempting to simply throw an exception and have a Trap capture the
offending [classname]+Tuple+. However, Traps were not designed as a filtering
mechanism, and consequently much valuable information is lost when Traps are
used in this situation.

Instead of Traps, use Filters. Create a [classname]+SubAssembly+ that applies
rules to the stream by setting a binary field that marks the [classname]+Tuple+
as good or bad. After all the rules are applied, split the stream based on the
value of the good or bad [classname]+Boolean+ value. Consider setting a reason
field that states why the [classname]+Tuple+ was marked bad.

=== Maintaining State in Operations

When creating custom Operations ([classname]+Function+, [classname]+Filter+,
[classname]+Aggregator+, or [classname]+Buffer+), do not store the Operation
state in class fields.

For example, if implementing an [classname]+Aggregator+ as a custom "counter,"
do not create a field named "count" and increment it on every
[methodname]+Aggregator.aggregate()+ call.

There is no guarantee that your Operation will be called from a single thread in
a JVM. Also, future versions of Hadoop or Cascading local mode might execute the
same Operation from multiple threads.

=== Fields Constants

Instead of interspersing String field names throughout the code, create an
interface that holds a constant value for each field name:

[source,java]
----
public static Fields FIRST_NAME = new Fields( "firstname", String.class );
public static Fields LAST_NAME = new Fields( "lastname", String.class );
----

Using the Fields class, instead of String, allows for building more complex
constants:

[source,java]
----
public static Fields FULL_NAME = FIRST_NAME.append( LAST_NAME );
----

TIP: Always declare the canonical type for each field. When building more
complex Fields instances from predefined constant Fields, the type information
is retained.

=== Checking the Source Code

When in doubt, look at the Cascading source code. If something is not documented
in this _User Guide_ or Javadoc and it's a feature of Cascading, the feature
source code or *unit tests* will give you clear instructions on what to do or
expect.

TIP: Maven users should configure their builds to pull [code]+*-sources.jar+ and
[code]+*-javadoc.jar+ files so that the IDE can allow seamless navigation
between developer and Cascading source.
