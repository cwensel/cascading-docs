:doctitle: {_doctitle} - Pipe Assemblies

include::_toc.adoc[]

== Pipe Assemblies

[[each-every]]
=== Each and Every Pipes

The [classname]+Each+ and [classname]+Every+ pipes perform operations on tuple
data -- for instance, perform a search-and-replace on tuple contents, filter out
some of the tuples based on their contents, or count the number of tuples in a
stream that share a common field value.

Here is the syntax for these pipes:

[source,java]
----
new Each( previousPipe, argumentSelector, operation, outputSelector )
----

[source,java]
----
new Every( previousPipe, argumentSelector, operation, outputSelector )
----

Both types take the following arguments on the constructor:

* incoming Pipe instance
* argument selector
* Operation instance
* output selector

NOTE: "Selectors" are Fields instances that define the field positions and names
that should be retrieved or returned.

The key difference between [classname]+Each+ and [classname]+Every+ is that an
[classname]+Each+ pipe operates on individual tuples, and an [classname]+Every+
pipe operates on groups of tuples sent out by [classname]+GroupBy+ or
[classname]+CoGroup+ pipes.

An [classname]+Each+ pipe applies operations that are subclasses of the
[classname]+Function+ and [classname]+Filter+ classes (described in the
Javadoc). For example, using [classname]+Each+ you can parse lines from a log
file into their constituent fields, filter out all lines except the HTTP GET
requests, and replace the "time string" fields with date fields.

Similarly, since the [classname]+Every+ pipe works on tuple groups (the output
of a [classname]+GroupBy+ or [classname]+CoGroup+ pipe), it applies operations
that are subclasses of [classname]+Aggregators+ and [classname]+Buffers+. For
example, you could use [classname]+GroupBy+ to group the output of the above
[classname]+Each+ pipe by date, then use an [classname]+Every+ pipe to count the
"GET" requests per date. The pipe would then emit the operation results as the
date and count for each group.

image:images/pipe-operation-relationship.svg[align="center"]

In the syntax shown at the start of this section, the _argument selector_
specifies fields from the input tuple to use as input values. If the argument
selector is not specified, the whole input tuple ([code]+Fields.ALL+) is
passed to the operation as a set of argument values.

Most [classname]+Operation+ subclasses declare result fields (shown as "declared
fields" in the diagram). The _output selector_ specifies the fields of the
output [classname]+Tuple+ from the fields of the input [classname]+Tuple+ and
the operation result. This new output [classname]+Tuple+ becomes the input
[classname]+Tuple+ to the next pipe in the pipe assembly. If the output selector
is [code]+Fields.ALL+, the output is the input [classname]+Tuple+ plus the
operation result, merged into a single [classname]+Tuple+.

Note that it is possible for a [classname]+Function+, [classname]+Aggregator+,
or [classname]+Buffer+ to return more than one output [classname]+Tuple+ per
input [classname]+Tuple+. In this case, the input tuple is duplicated as many
times as necessary to create the necessary output tuples. This is similar to the
reiteration of values that happens during a join. If a function is designed to
always emit three result tuples for every input tuple, each of the three
outgoing tuples will consist of the selected input tuple values plus one of the
three sets of function result values.

image:images/each-operation-relationship.svg[align="center"]

If the result selector is not specified for an [classname]+Each+ pipe performing
a [classname]+Functions+ operation, the operation results are returned by
default ([code]++Fields.RESULTS++), discarding the input tuple values in the
tuple stream. (This is not true of [classname]++Filters++ , which either discard
the input tuple or return it intact, and thus do not use an output selector.)

image:images/every-operation-relationship.svg[align="center"]

For the [classname]+Every+ pipe, the [classname]+Aggregator+ results are
appended to the input Tuple ([code]+Fields.ALL+) by default.

Note that the [classname]+Every+ pipe associates [classname]+Aggregator+ results
with the current group [classname]+Tuple+ (the unique keys that define the
group). For example, if you are grouping on the field "department" and
counting the number of "names" grouped by that department, the resulting output
Fields will be `["department","num_employees"]`.

If you are also adding up the salaries associated with each "name" in each
"department", the output Fields will be
`["department","num_employees","total_salaries"]`.

This is only true for chains of [classname]+Aggregator+ Operations -- you are
not allowed to chain [classname]+Buffer+ operations, as explained below.

image:images/buffer-operation-relationship.svg[align="center"]

When the [classname]+Every+ pipe is used with a [classname]+Buffer+ operation,
instead of an [classname]+Aggregator+, the behavior is different. Instead of
being associated with the current grouping tuple, the operation results are
associated with the current values tuple. This is analogous to how an
[classname]+Each+ pipe works with a [classname]+Function+. This approach may
seem slightly unintuitive, but provides much more flexibility.

To put it another way, the results of the buffer operation appends the current
keys that define the group only if appending the keys is relevant. It is also
possible for a Buffer to return more than one result Tuple per unique grouping.
A [classname]+Buffer+ may or may not emulate an [classname]+Aggregator+ in cases
where an [classname]+Aggregator+ is just a special optimized case of a
[classname]+Buffer+.

=== Merge

The [classname]+Merge+ pipe is very simple. It accepts two or more streams that
have the same fields, and emits a single stream containing all the tuples from
all the input streams. Thus a merge is just a mingling of all the tuples from
the input streams, as if shuffling multiple card decks into one. Note that the
output of [classname]+Merge+ is in arbitrary order.

.Merging two tuple streams
====
include::_simple-merge.adoc[]
====

The example above simply combines all the tuples from two existing streams
("lhs" and "rhs") into a new tuple stream ("merge").

=== GroupBy

[classname]+GroupBy+ groups the tuples of a stream based on common values in
specified fields. If passed multiple streams as inputs, it performs a merge
before the grouping. As with [classname]+Merge+, a [classname]+GroupBy+ requires
that multiple input streams share the same field structure.

The output of [classname]+GroupBy+ is suitable for the [classname]+Every+ pipe,
which performs [classname]+Aggregator+ and [classname]+Buffer+ operations, such
as counting, totaling, or averaging groups of tuples that have a common grouping
value (e.g., the same date). By default, [classname]+GroupBy+ performs no
secondary sort, so within each group the tuples are in arbitrary order. For
instance, when grouping on "lastname," the tuples [code]+[doe, john]+ and
[code]+[doe, jane]+ are placed in arbitrary sequence of the same group.

[[secondary-sorting]]
==== Secondary Sorting

If multilevel sorting is desired, the names of the sort fields must be
specified to the [classname]+GroupBy+ instance, as seen below. In this example,
[code]+value1+ and [code]+value2+ arrive in their natural sort order
(assuming they can implement [classname]++java.lang.Comparable++).

.Secondary sorting
====
include::_simple-groupby-secondary.adoc[]
====

If the developer does not care about the order of [code]+value2+, it can be
omitted from the [code]+sortFields+ [classname]+Fields+ constructor.

In the next example, we reverse the order of [code]+value1+ while keeping the
natural order of [code]+value2+.

.Reversing secondary sort order
====
include::_simple-groupby-secondary-comparator.adoc[]
====

Whenever there is an implied sort during grouping or secondary sorting, a custom
[classname]+java.util.Comparator+ can optionally be supplied to the grouping
[classname]+Fields+ or secondary sort [classname]+Fields+. This allows the
developer to use the [code]+Fields.setComparator()+ call to control the sort.

To sort or group on non-Java-comparable classes, consider creating a custom
[classname]+Comparator+.

The following example is more practical: fields are grouped by the "day of the
year", but the code reverses the order of the tuples within that grouping by
"time of day".

.Reverse order by time
====
include::_simple-groupby-secondary-time.adoc[]
====

=== CoGroup

The [classname]+CoGroup+ pipe is similar to [classname]+GroupBy+. This pipe
performs a join instead of a merge. [classname]+CoGroup+ accepts two or more
input streams and groups them on one or more specified keys. The join operation
is performed on equal key values, similar to a SQL join.

The output stream contains all the fields in the input streams.

As with SQL, the join can be inner, outer, left, or right. Self-joins are
permitted, as well as mixed joins (for three or more streams) and custom joins.
Null fields in the input streams become corresponding null fields in the output
stream.

Since the output is grouped, it is suitable for the [classname]+Every+ pipe,
which performs [classname]+Aggregator+ and [classname]+Buffer+ operations --
such as counting, totaling, or averaging groups of tuples that have a common
value (e.g., the same date).

The output stream is sorted by the natural order of the grouping fields. To
control this order, at least the first [classname]+groupingFields+ value given
should be an instance of [classname]+Fields+ containing [classname]+Comparator+
instances for the appropriate fields. This allows fine-grained control of the
sort grouping order.

==== Field Names

In a join operation, all the field names used in any of the input tuples must be
unique; duplicate field names are not allowed. If the names overlap there is a
collision, as shown in the following diagram.

image:images/cogrouping-fields-fail.svg[align="center"]

In this figure, two streams are to be joined on the "url" field, resulting in a
new Tuple that contains fields from the two input tuples. However, the resulting
tuple would include two fields with the same name ("url"), which is unworkable.
To handle the conflict, developers can use the [parameter]+declaredFields+
argument (described in the Javadoc) to declare unique field names for the output
tuple, as in the following example.

.Joining two tuple streams with duplicate field names
====
include::_duplicate-cogroup.adoc[]
====

image:images/cogrouping-fields-pass.svg[align="center"]

This revised figure demonstrates the use of declared field names to prevent a
planning failure.

It might seem preferable for Cascading to automatically recognize the
duplication and simply merge the identically named fields, saving effort for the
developer. However, consider the case of an outer type join in which one field
(or set of fields used for the join) for a given join side happens to be
[code]+null+. Discarding one of the duplicate fields would lose this
information.

Further, the internal implementation for reading tuples relies on field position
and not field names. The field names are a device for the developer. This
approach allows the behavior of the [classname]+CoGroup+ to be deterministic and
consistent.

[[joiner-class]]
==== The Joiner class

In Example 5, a Joiner class (InnerJoin) is specified to perform a join on our
data. There are five Joiner subclasses, as shown in the following diagram.

image:images/joins.svg[align="center"]

In [classname]+CoGroup+, the join is performed after all the input streams are
first co-grouped by their common keys. Cascading must create a "bag" of data for
every grouping in the input streams, consisting of all the [classname]+Tuple+
instances associated with that grouping.

image:images/cogrouped-values.svg[align="center"]

As mentioned previously, joins in Cascading are analogous to joins in SQL. The
most commonly used type of join is the inner join, which is the default in
[classname]+CoGroup+. An inner join tries to match _each_ Tuple on the "lhs"
with _every_ Tuple on the "rhs," based on matching fields values. If either side
of an inner join has no tuples for a given value, no tuples are joined. An outer
join, conversely, allows for either side to be empty and simply substitutes a
[classname]+Tuple+ containing [code]+null+ values for the nonexistent tuple.

The following sample data is used in the discussion below to explain and compare
the different types of join:

----
LHS = [0,a] [1,b] [2,c]
RHS = [0,A] [2,C] [3,D]
----

In each join type below, the values are joined on the first tuple position (the
join key), which is a numeric value. Note that, when Cascading joins tuples, the
resulting [classname]+Tuple+ contains all the incoming values from incoming
tuple streams, and does not discard the duplicate key fields. As mentioned
above, on outer joins where there is no equivalent key in the alternate stream,
[code]+null+ values are used.

For example using the data above, the result Tuple of an inner join with join
key value of [code]+2+ would be [code]+[2,c,2,C]+. The result Tuple of an outer
join with join key value of [code]+1+ would be [code]+[1,b,null,null]+.

InnerJoin::

An inner join only returns a joined [classname]+Tuple+ if neither bag for the
join key is empty.

+

----
[0,a,0,A] [2,c,2,C]
----

OuterJoin::

An outer join performs a join if one bag (left or right) for the join key is
empty or if neither bag is empty.

+

----
[0,a,0,A] [1,b,null,null] [2,c,2,C] [null,null,3,D]
----

LeftJoin::

A left join can also be stated as a left inner and right outer join, where it is
acceptable for the right bag to be empty (but not the left).

+

----
[0,a,0,A] [1,b,null,null] [2,c,2,C]
----

RightJoin::

A right join can also be stated as a left outer and right inner join, where it
is acceptable for the left bag to be empty (but not the right).

+

----
[0,a,0,A] [2,c,2,C] [null,null,3,D]
----

MixedJoin::

A mixed join is where 3 or more tuple streams are joined, using a small Boolean
array to specify each of the join types to use. For more information, see the
[classname]+cascading.pipe.cogroup.MixedJoin+ class in the Javadoc.

_Custom_::

Developers can use the [classname]+cascading.pipe.cogroup.Joiner+ class as a
subclass to create custom join operations.

==== Scaling

[classname]+CoGroup+ attempts to store the entire unique-keys tuple "bag" from
the right-hand stream in memory for rapid joining to the left-hand stream. If
the bag is very large, it may exceed a configurable threshold and be spilled to
disk, reducing performance and potentially causing a memory error (if the
threshold value is too large). Thus it is usually best to put the stream with
the largest groupings on the left-hand side and, if necessary, adjust the spill
threshold as described in the Javadoc.

=== HashJoin

[classname]+HashJoin+ performs a join (similar to a SQL join) on two or more
streams, and emits a stream of tuples that contain fields from all of the input
streams. With a join, the tuples in the different input streams do not typically
contain the same set of fields.

As with [classname]+CoGroup+, the field names must all be unique, including the
names of the key fields, to avoid duplicate field names in the emitted
[classname]+Tuple+. If necessary, use the [parameter]+declaredFields+ argument
to specify unique field names for the output.

An inner join is performed by default, but you can choose inner, outer, left,
right, or mixed (three or more streams). Self-joins are permitted. Developers
can also create custom Joiners if desired. For more information on types of
joins, refer to <<joiner-class>> or the Javadoc.

.Joining two tuple streams
====
include::_simple-join.adoc[]
====

The example above performs an inner join on two streams ("lhs" and "rhs"), based
on common values in two fields. The field names that are specified in
[classname]+lhsFields+ and [classname]+rhsFields+ are among the field names
previously declared for the two input streams.

==== Scaling

For joins that do not require grouping, [classname]+HashJoin+ provides faster
execution than [classname]+CoGroup+, but it operates within stricter
limitations. It is optimized for joining one or more small streams to no more
than one large stream.

Unlike [classname]+CoGroup+, [classname]+HashJoin+ attempts to keep the entire
right-hand stream in memory for rapid comparison (not just the current grouping,
as no grouping is performed for a [classname]++HashJoin++). Thus a very large
tuple stream in the right-hand stream may exceed a configurable spill-to-disk
threshold, reducing performance and potentially causing a memory error. For this
reason, it's advisable to use the smaller stream on the right-hand side.
Additionally, it may be helpful to adjust the spill threshold as described in
the Javadoc.

NOTE: Due to the potential difficulties of using [classname]+HashJoin+ (as
compared to the slower but much more reliable [classname]++CoGroup++),
developers should thoroughly understand this class before attempting to use it
in a production environment.

TIP: Frequently the [classname]+HashJoin+ is fed a filtered-down stream of
Tuples from what was originally a very large file. To prevent the large file
from being replicated throughout a cluster, use a [classname]+Checkpoint+ pipe
at the point where the data has been filtered down to its smallest prior to
entering a [classname]+HashJoin+. The Tuple stream will persist on disk. A new
[classname]+FlowStep+ (MapReduce job) is created to read the smaller data size
more efficiently. *Not all platforms support checkpointing.*
