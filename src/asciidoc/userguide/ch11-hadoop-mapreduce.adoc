:toc2:
:doctitle: {_doctitle} - Apache Hadoop MapReduce Platform

== Apache Hadoop MapReduce Platform

=== Configuring Applications

During runtime, Hadoop must be told which application jar file should be pushed
to the cluster. Typically, this is done via the Hadoop API [classname]+JobConf+
object.

Cascading offers a shorthand for configuring this parameter, demonstrated here:

Above we see two ways to set the same property - via the
[methodname]+setJarClass()+ method, and via the [methodname]+setJarPath()+
method. One is based on a Class name, and the other is based on a literal path.

The first method takes a Class object that owns the "main" function for this
application. The assumption here is that [code]+Main.class+ is not located in a
Java Jar that is stored in the _lib_ folder of the application Jar. If it is,
that Jar is pushed to the cluster, not the parent application jar.

The second method simply sets the path to the Java Jar as a property.

In your application, only one of these methods needs to be called, but one of
them must be called to properly configure Hadoop.

.Configuring the Application Jar with a JobConf
====
include::flow-jobconf.adoc[]
====

Above we are starting with an existing Hadoop [classname]+JobConf+ instance and
building a Properties object with it as the default.

Note that [classname]+AppProps+ is a helper fluent API for setting properties
that define Flows or configure the underlying platform.

=== Creating Flows from a JobConf

If a MapReduce job already exists and needs to be managed by a Cascade, then the
[classname]+cascading.flow.hadoop.MapReduceFlow+ class should be used. To do
this, after creating a Hadoop [classname]+JobConf+ instance simply pass it into
the [classname]+MapReduceFlow+ constructor. The resulting [classname]+Flow+
instance can be used like any other Flow.

[[building]]
=== Building

Cascading ships with several jars and dependencies in the download
archive. Alternatively, Cascading is available over Maven and Ivy
through the Conjars repository, along with a number of other
Cascading-related projects. See http://conjars.org for more
information.

The core Cascading artifacts include the following:

cascading-core-2.6.x.jar::
This jar contains the Cascading Core class files. It should
be packaged with _lib/*.jar_ when using
Hadoop.


cascading-local-2.6.x.jar::
This jar contains the Cascading local mode class files. It
is not needed when using Hadoop.


cascading-hadoop-2.6.x.jar::
This jar contains the Cascading Hadoop 1 specific
dependencies. It should be packaged with
_lib/*.jar_ when using Hadoop.


cascading-hadoop2-mr1-2.6.x.jar::
This jar contains the Cascading Hadoop 2 specific
dependencies. It should be packaged with
_lib/*.jar_ when using Hadoop.


cascading-xml-2.6.x.jar::
This jar contains Cascading XML module class files and is
optional. It should be packaged with
_lib/xml/*.jar_ when using Hadoop.


Cascading works with either of the Hadoop processing modes - the
default local standalone mode and the distributed cluster mode. As
specified in the Hadoop documentation, running in cluster mode requires
the creation of a Hadoop job jar that includes the Cascading jars, plus
any needed third-party jars, in its _lib_ directory.
This is true regardless of whether they are Cascading Hadoop-mode
applications or raw Hadoop MapReduce applications.
