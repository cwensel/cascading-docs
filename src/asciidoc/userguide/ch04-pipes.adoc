:toc2:
:doctitle: {_doctitle} - Pipe Assemblies

= Pipe Assemblies

[[each-every]]
== The Each and Every Pipes

The [classname]+Each+ and [classname]+Every+
pipes perform operations on tuple data - for instance, perform a
search-and-replace on tuple contents, filter out some of the tuples
based on their contents, or count the number of tuples in a stream
that share a common field value.

Here is the syntax for these pipes:


----
new Each( previousPipe, argumentSelector, operation, outputSelector )
----




----
new Every( previousPipe, argumentSelector, operation, outputSelector )
----



Both types take four arguments:

* a Pipe instance
* an argument selector
* an Operation instance
*
an output selector on the constructor (selectors here are
Fields instances)







The key difference between [classname]+Each+ and
[classname]+Every+ is that the [classname]+Each+
operates on individual tuples, and [classname]+Every+
operates on groups of tuples emitted by [classname]+GroupBy+
or [classname]+CoGroup+. This affects the kind of operations
that these two pipes can perform, and the kind of output they produce
as a result.

The [classname]+Each+ pipe applies operations that are
subclasses of [classname]+Functions+ and
[classname]+Filters+ (described in the Javadoc). For
example, using [classname]+Each+ you can parse lines from a
logfile into their constituent fields, filter out all lines except the
HTTP GET requests, and replace the timestring fields with date
fields.

Similarly, since the [classname]+Every+ pipe works on
tuple groups (the output of a [classname]+GroupBy+ or
[classname]+CoGroup+ pipe), it applies operations that are
subclasses of [classname]+Aggregators+ and
[classname]+Buffers+. For example, you could use
[classname]+GroupBy+ to group the output of the above
[classname]+Each+ pipe by date, then use an
[classname]+Every+ pipe to count the GET requests per date.
The pipe would then emit the operation results as the date and count
for each group.

image:images/pipe-operation-relationship.svg[align="center"]

In the syntax shown at the start of this section, the _argument selector_ specifies fields from the
input tuple to use as input values. If the argument selector is not
specified, the whole input tuple ([code]++Fields.ALL++) is passed
to the operation as a set of argument values.

Most [classname]+Operation+ subclasses declare result
fields (shown as "declared fields" in the diagram). The _output selector_ specifies the fields of the
output [classname]+Tuple+ from the fields of the input
[classname]+Tuple+ and the operation result. This new output
[classname]+Tuple+ becomes the input
[classname]+Tuple+ to the next pipe in the pipe assembly. If
the output selector is [code]+Fields.ALL+, the output is the
input [classname]+Tuple+ plus the operation result, merged
into a single [classname]+Tuple+.

Note that it's possible for a [classname]+Function+ or
[classname]+Aggregator+ to return more than one output
[classname]+Tuple+ per input [classname]+Tuple+.
In this case, the input tuple is duplicated as many times as necessary
to create the necessary output tuples. This is similar to the
reiteration of values that happens during a join. If a function is
designed to always emit three result tuples for every input tuple,
each of the three outgoing tuples will consist of the selected input
tuple values plus one of the three sets of function result
values.

image:images/each-operation-relationship.svg[align="center"]

If the result selector is not specified for an
[classname]+Each+ pipe performing a
[classname]+Functions+ operation, the operation results are
returned by default ([code]++Fields.RESULTS++), discarding the
input tuple values in the tuple stream. (This is not true of
[classname]++Filters++ , which either discard the input tuple
or return it intact, and thus do not use an output selector.)

image:images/every-operation-relationship.svg[align="center"]

For the [classname]+Every+ pipe, the Aggregator
results are appended to the input Tuple ([code]++Fields.ALL++) by
default.

Note that the [classname]+Every+ pipe associates
[classname]+Aggregator+ results with the current group
[classname]+Tuple+ (the unique keys currently being grouped
on). For example, if you are grouping on the field "department" and
counting the number of "names" grouped by that department, the
resulting output Fields will be ["department","num_employees"].

If you are also adding up the salaries associated with each
"name" in each "department", the output Fields will be
["department","num_employees","total_salaries"].

This is only true for chains of
[classname]+Aggregator+ Operations - you are not allowed to
chain [classname]+Buffer+ operations, as explained
below.

image:images/buffer-operation-relationship.svg[align="center"]

When the [classname]+Every+ pipe is used with a
[classname]+Buffer+ operation, instead of an
[classname]+Aggregator+, the behavior is different. Instead
of being associated with the current grouping tuple, the operation
results are associated with the current values tuple. This is
analogous to how an [classname]+Each+ pipe works with a
[classname]+Function+. This approach may seem slightly
unintuitive, but provides much more flexibility. To put it another
way, the results of the buffer operation are not appended to the
current keys being grouped on. It is up to the buffer to emit them if
they are relevant. It is also possible for a Buffer to emit more than
one result Tuple per unique grouping. That is, a Buffer may or may not
emulate an Aggregator, where an Aggregator is just a special optimized
case of a Buffer.

For more information on how operations process fields, see <<field-processing>> .



== Merge

The [classname]+Merge+ pipe is very simple. It accepts
two or more streams that have the same fields, and emits a single
stream containing all the tuples from all the input streams. Thus a
merge is just a mingling of all the tuples from the input streams, as
if shuffling multiple card decks into one. Note that the output of
[classname]+Merge+ is in arbitrary order.

.Merging Two Tuple Streams
====
include::simple-merge.adoc[]
====

The example above simply combines all the tuples from two
existing streams ("lhs" and "rhs") into a new tuple stream
("merge").



== GroupBy

[classname]+GroupBy+ groups the tuples of a stream
based on common values in a specified field. If passed multiple
streams as inputs, it performs a merge before the grouping. As with
[classname]+Merge+, a [classname]+GroupBy+
requires that multiple input streams share the same field
structure.

The output of [classname]+GroupBy+ is suitable for the
[classname]+Every+ pipe, which performs
[classname]+Aggregator+ and [classname]+Buffer+
operations, such as counting, totalling, or averaging groups of tuples
that have a common value (e.g., the same date). By default,
[classname]+GroupBy+ performs no secondary sort, so within
each group the tuples are in arbitrary order. For instance, when
grouping on "lastname", the tuples [code]+[doe, john]+ and
[code]+[doe, jane]+ end up in the same group, but in arbitrary
sequence.



[[secondary-sorting]]
=== Secondary sorting

If multi-level sorting is desired, the names of the sort
fields on must be specified to the [classname]+GroupBy+
instance, as seen below. In this example, [code]+value1+ and
[code]+value2+ will arrive in their natural sort order
(assuming they are
[classname]++java.lang.Comparable++).

.Secondary Sorting
====
include::simple-groupby-secondary.adoc[]
====

If we don't care about the order of [code]+value2+, we
can leave it out of the [code]+sortFields+
[classname]+Fields+ constructor.

In the next example, we reverse the order of
[code]+value1+ while keeping the natural order of
[code]+value2+.

.Reversing Secondary Sort Order
====
include::simple-groupby-secondary-comparator.adoc[]
====

Whenever there is an implied sort during grouping or secondary
sorting, a custom [classname]+java.util.Comparator+ can
optionally be supplied to the grouping [classname]+Fields+
or secondary sort [classname]+Fields+. This allows the
developer to use the [code]+Fields.setComparator()+ call to
control the sort.

To sort or group on non-Java-comparable classes, consider
creating a custom [classname]+Comparator+.

Below is a more practical example, where we group by the "day
of the year", but want to reverse the order of the tuples within
that grouping by "time of day".

.Reverse Order by Time
====
include::simple-groupby-secondary-time.adoc[]
====



== CoGroup

The [classname]+CoGroup+ pipe is similar to
[classname]+GroupBy+, but instead of a merge, performs a
join. That is, [classname]+CoGroup+ accepts two or more
input streams and groups them on one or more specified keys, and
performs a join operation on equal key values, similar to a SQL
join.

The output stream contains all the fields from all the input
streams.

As with SQL, the join can be inner, outer, left, or right.
Self-joins are permitted, as well as mixed joins (for three or more
streams) and custom joins. Null fields in the input streams become
corresponding null fields in the output stream.

Since the output is grouped, it is suitable for the
[classname]+Every+ pipe, which performs
[classname]+Aggregator+ and [classname]+Buffer+
operations - such as counting, totalling, or averaging groups of
tuples that have a common value (e.g., the same date).

The output stream is sorted by the natural order of the grouping
fields. To control this order, at least the first
[classname]+groupingFields+ value given should be an
instance of [classname]+Fields+ containing
[classname]+Comparator+ instances for the appropriate
fields. This allows fine-grained control of the sort grouping
order.



=== Field names

In a join operation, all the field names used in any of the
input tuples must be unique; duplicate field names are not allowed.
If the names overlap there is a collision, as shown in the following
diagram.

image:images/cogrouping-fields-fail.svg[align="center"]

In this figure, two streams are to be joined on the "url"
field, resulting in a new Tuple that contains fields from the two
input tuples. However, the resulting tuple would include two fields
with the same name ("url"), which is unworkable. To handle the
conflict, developers can use the
[parameter]+declaredFields+ argument (described in the
Javadoc) to declare unique field names for the output tuple, as in
the following example.

.Joining Two Tuple Streams with Duplicate Field Names
====
include::duplicate-cogroup.adoc[]
====

image:images/cogrouping-fields-pass.svg[align="center"]

This revised figure demonstrates the use of declared field
names to prevent a planning failure.

It might seem preferable for Cascading to automatically
recognize the duplication and simply merge the identically-named
fields, saving effort for the developer. However, consider the case
of an outer type join in which one field (or set of fields used for
the join) for a given join side happens to be [code]+null+.
Discarding one of the duplicate fields would lose this
information.

Further, the internal implementation relies on field position,
not field names, when reading tuples; the field names are a device
for the developer. This approach allows the behavior of the
[classname]+CoGroup+ to be deterministic and
predictable.



[[joiner-class]]
=== The Joiner class

In the example above, we explicitly specified a Joiner class
(InnerJoin) to perform a join on our data. There are five Joiner
subclasses, as shown in this diagram.

image:images/joins.svg[align="center"]

In [classname]+CoGroup+, the join is performed after
all the input streams are first co-grouped by their common keys.
Cascading must create a "bag" of data for every grouping in the
input streams, consisting of all the [classname]+Tuple+
instances associated with that grouping.

image:images/cogrouped-values.svg[align="center"]

It's already been mentioned that joins in Cascading are
analogous to joins in SQL. The most commonly-used type of join is
the inner join, the default in [classname]+CoGroup+. An
inner join tries to match _each_
Tuple on the "lhs" with _every_
Tuple on the "rhs", based on matching field values. With an inner
join, if either side has no tuples for a given value, no tuples are
joined. An outer join, conversely, allows for either side to be
empty and simply substitutes a [classname]+Tuple+
containing [code]+null+ values for the non-existent
tuple.

This sample data is used in the discussion below to explain
and compare the different types of join:


----
LHS = [0,a] [1,b] [2,c]
RHS = [0,A] [2,C] [3,D]
----

In each join type below, the values
are joined on the first tuple position (the join key), a numeric
value. Note that, when Cascading joins tuples, the resulting
[classname]+Tuple+ contains all the incoming values from
in incoming tuple streams, and does not discard the duplicate key
fields. As mentioned above, on outer joins where there is no
equivalent key in the alternate stream, [code]+null+ values are
used.

For example using the data above, the result Tuple of an
"inner" join with join key value of [code]+2+ would be
[code]+[2,c,2,C]+. The result Tuple of an "outer" join with
join key value of [code]+1+ would be
[code]+[1,b,null,null]+.

InnerJoin::
An inner join only returns a joined
[classname]+Tuple+ if neither bag for the join key
is empty.
+
----
[0,a,0,A] [2,c,2,C]
----



OuterJoin::
An outer join performs a join if one bag (left or
right) for the join key is empty, or if neither bag is
empty.
----
[0,a,0,A] [1,b,null,null] [2,c,2,C] [null,null,3,D]
----




LeftJoin::
A left join can also be stated as a left inner and
right outer join, where it is acceptable for the right bag
to be empty (but not the left).



+
----
[0,a,0,A] [1,b,null,null] [2,c,2,C]
----

RightJoin::
A right join can also be stated as a left outer and
right inner join, where it is acceptable for the left bag to
be empty (but not the right).
----
[0,a,0,A] [2,c,2,C] [null,null,3,D]
----




MixedJoin::
A mixed join is where 3 or more tuple streams are
joined, using a small Boolean array to specify each of the
join types to use. For more information, see the
[classname]+cascading.pipe.cogroup.MixedJoin+
class in the Javadoc.


_Custom_::
Developers can subclass the
[classname]+cascading.pipe.cogroup.Joiner+ class
to create custom join operations.






=== Scaling

[classname]+CoGroup+ attempts to store the entire
current unique keys tuple "bag" from the right-hand stream in memory
for rapid joining to the left-hand stream. If the bag is very large,
it may exceed a configurable threshold and be spilled to disk,
reducing performance and potentially causing a memory error (if the
threshold value is too large). Thus it's usually best to put the
stream with the largest groupings on the left-hand side and, if
necessary, adjust the spill threshold as described in the
Javadoc.



== HashJoin

[classname]+HashJoin+ performs a join (similar to a
SQL join) on two or more streams, and emits a stream of tuples that
contain fields from all of the input streams. With a join, the tuples
in the different input streams do not typically contain the same set
of fields.

As with [classname]+ CoGroup+, the field names must
all be unique, including the names of the key fields, to avoid
duplicate field names in the emitted [classname]+Tuple+. If
necessary, use the [parameter]+declaredFields+ argument to
specify unique field names for the output.

An inner join is performed by default, but you can choose inner,
outer, left, right, or mixed (three or more streams). Self-joins are
permitted. Developers can also create custom Joiners if desired. For
more information on types of joins, refer to <<joiner-class>> or the Javadoc.

.Joining Two Tuple Streams
====
include::simple-join.adoc[]
====

The example above performs an inner join on two streams ("lhs"
and "rhs"), based on common values in two fields. The field names that
are specified in [classname]+lhsFields+ and
[classname]+rhsFields+ are among the field names previously
declared for the two input streams.



=== Scaling

For joins that do not require grouping,
[classname]+HashJoin+ provides faster execution than
[classname]+CoGroup+, but it operates within stricter
limitations. It is optimized for joining one or more small streams
to no more than one large stream.

Unlike [classname]+CoGroup+,
[classname]+HashJoin+ attempts to keep the entire
right-hand stream in memory for rapid comparison (not just the
current grouping, as no grouping is performed for a
[classname]++HashJoin++). Thus a very large tuple stream in
the right-hand stream may exceed a configurable spill-to-disk
threshold, reducing performance and potentially causing a memory
error. For this reason, it's advisable to use the smaller stream on
the right-hand side. Additionally, it may be helpful to adjust the
spill threshold as described in the Javadoc.

Due to the potential difficulties of using
[classname]+HashJoin+ (as compared to the slower but much
more reliable [classname]++CoGroup++), developers should
thoroughly understand this class before attempting to use it.

Frequently the [classname]+HashJoin+ is fed a
filtered down stream of Tuples from what was originally a very large
file. To prevent the large file from being replicated throughout a
cluster, when running in Hadoop mode, use a
[classname]+Checkpoint+ pipe at the point where the data
has been filtered down to its smallest before it is streamed into a
[classname]+HashJoin+. This will force the Tuple stream to
be persisted to disk and new [classname]+FlowStep+
(MapReduce job) to be created to read the smaller data size more
efficiently.
